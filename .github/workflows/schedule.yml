- name: Run Scraper
      # NOVO BLOCO: Força o GitHub a liberar os segredos
      env:
        SUPABASE_URL: ${{ https://sjlcecjluuyrqwznwkcg.supabase.co }}
        SUPABASE_KEY: ${{ eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InNqbGNlY2psdXV5cnF3em53a2NnIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2MzM5MDM3MCwiZXhwIjoyMDc4OTY2MzcwfQ.3boxrrak80EdAulnnOxhjBkB8uC7OPlRJsDfoaisEac }}
      run: |
        python -m scrapy runspider pepe_scraper.py

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *' # Roda todos os dias à meia-noite UTC

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      # 1. Configura o ambiente Python (Corrige o erro de 'python: not found')
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.10'

      # 2. Instala as bibliotecas
      - name: Install dependencies
        run: pip install scrapy supabase

      # 3. Executa o Scraper (Comando robusto para servidores)
      - name: Run Scraper
        run: |
          python -m scrapy runspider pepe_scraper.py
